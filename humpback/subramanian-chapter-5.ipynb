{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = torchvision.datasets.MNIST('data/', train=True, download=True, transform=transformation)\n",
    "# test_dataset = torchvision.datasets.MNIST('data/', train=False, download=True, transform=transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader_iter = train_loader.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(image):\n",
    "    image = image.numpy()[0]\n",
    "    mean = 0.1307\n",
    "    std = 0.3081\n",
    "    image = ((mean * image) + std)\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_data = train_loader_iter.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_img(sample_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_img(sample_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n",
    "#         self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)\n",
    "#         self.conv2_drop = torch.nn.Dropout2d()\n",
    "#         self.fc1 = torch.nn.Linear(320, 50)\n",
    "#         self.fc2 = torch.nn.Linear(50, 10)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         x = x.view(-1, 320)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.fc2(x)\n",
    "#         return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = torch.nn.Conv2d(3, 10, kernel_size=5)\n",
    "#         self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)\n",
    "#         self.conv2_drop = torch.nn.Dropout2d()\n",
    "#         self.fc1 = torch.nn.Linear(56180, 500)\n",
    "#         #self.fc1 = torch.nn.Linear(67840, 53)\n",
    "#         self.fc2 = torch.nn.Linear(500, 50)\n",
    "#         #self.fc2 = torch.nn.Linear(53, 50)\n",
    "#         self.fc3 = torch.nn.Linear(50, 2)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.fc3(x)\n",
    "#         return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv = torch.nn.Conv1d(1, 1, 3, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = torch.randn(1, 1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv(Variable(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# simple_transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Scale((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = torchvision.datasets.ImageFolder('chapter3/dogsandcats/train/', simple_transform)\n",
    "#valid = torchvision.datasets.ImageFolder('chapter3/dogsandcats/valid/', simple_transform)\n",
    "train = torchvision.datasets.ImageFolder('chapter3/dogsandcats/train/', train_transform)\n",
    "valid = torchvision.datasets.ImageFolder('chapter3/dogsandcats/valid/', train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = torch.utils.data.DataLoader(train, batch_size=64, num_workers=8)\n",
    "valid_data_gen = torch.utils.data.DataLoader(valid, batch_size=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_data_gen\n",
    "test_loader = valid_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, data_loader, phase='training', volatile=False):\n",
    "    if is_cuda:\n",
    "        model = model.cuda()\n",
    "    if phase == 'training':      \n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if is_cuda:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        data = Variable(data, volatile)\n",
    "        target = Variable(target)\n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        running_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
    "        #running_loss += (F.nll_loss(output, target, size_average=False)).item()\n",
    "        print(\"running_loss: \", running_loss)\n",
    "        preds = output.data.max(dim=1, keepdim=True)[1]\n",
    "        print(\"preds:\\n\", preds)\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    loss = running_loss / len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct / len(data_loader.dataset)\n",
    "    print(\n",
    "        f\"{phase}, loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct} / {len(data_loader.dataset)}\"\n",
    "        #\" {accuracy:{10}.{4}}\")\n",
    "        \"  {}\".format(accuracy))\n",
    "    return loss, accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if is_cuda:\n",
    "#    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "# train_losses = []\n",
    "# train_accuracy = []\n",
    "# val_losses = []\n",
    "# val_accuracy = []\n",
    "# for epoch in range(1, 20):\n",
    "#     epoch_loss, epoch_accuracy = fit(epoch, model, train_loader, phase='training')\n",
    "#     val_epoch_loss, val_epoch_accuracy = fit(epoch, model, test_loader, phase='validation')\n",
    "#     train_losses.append(epoch_loss)\n",
    "#     train_accuracy.append(epoch_accuracy)\n",
    "#     val_losses.append(val_epoch_loss)\n",
    "#     val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, len(train_losses) + 1), train_losses, 'bo', label=\"training loss\")\n",
    "# plt.plot(range(1, len(val_losses) + 1), val_losses, 'r', label=\"validation loss\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, 'bo', label=\"training accuracy\")\n",
    "# plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, 'r', label=\"validation accuracy\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.classifier[6].out_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(vgg.classifier.parameters(), lr=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.children():\n",
    "    if type(layer) == torch.nn.Dropout:\n",
    "        layer.p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracy = []\n",
    "val_losses = []\n",
    "val_accuracy = []\n",
    "for epoch in range(1, 10):\n",
    "    epoch_loss, epoch_accuracy = fit(epoch, vgg, train_loader, phase='training')\n",
    "    val_epoch_loss, val_epoch_accuracy = fit(epoch, vgg, test_loader, phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
